{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/Baileyswu/google-tensorflow-tutor/blob/master/7.%20logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4T-_IsVbweU"
   },
   "source": [
    " # 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEAHZv4rIYHX"
   },
   "source": [
    " **学习目标：**\n",
    "  * 将（在之前的练习中构建的）房屋价值中位数预测模型重新构建为二元分类模型\n",
    "  * 比较逻辑回归与线性回归解决二元分类问题的有效性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnkCZqdIIYHY"
   },
   "source": [
    " 与在之前的练习中一样，我们将使用加利福尼亚州住房数据集，但这次我们会预测某个城市街区的住房成本是否高昂，从而将其转换成一个二元分类问题。此外，我们还会暂时恢复使用默认特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pltCyy2K3dd"
   },
   "source": [
    " ## 将问题构建为二元分类问题\n",
    "\n",
    "数据集的目标是 `median_house_value`，它是一个数值（连续值）特征。我们可以通过向此连续值使用阈值来创建一个布尔值标签。\n",
    "\n",
    "我们希望通过某个城市街区的特征预测该街区的住房成本是否高昂。为了给训练数据和评估数据准备目标，我们针对房屋价值中位数定义了分类阈值 - 第 75 百分位数（约为 265000）。所有高于此阈值的房屋价值标记为 `1`，其他值标记为 `0`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67IJwZX1Vvjt"
   },
   "source": [
    " ## 设置\n",
    "\n",
    "运行以下单元格，以加载数据并准备输入特征和目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import pandas as pd\n",
    "\n",
    "def arff_to_csv(fpath):\n",
    "    #读取arff数据\n",
    "    if fpath.find('.arff') < 0:\n",
    "        print('the file is not .arff file')\n",
    "        return\n",
    "    f = open(fpath)\n",
    "    filename = fpath[:fpath.find('.arff')] + '.csv'\n",
    "    tof = open(filename, 'w+')\n",
    "    lines = f.readlines()\n",
    "    content = []\n",
    "    flag = 0\n",
    "    for x in lines:\n",
    "        if \"@relation\" in x or \"@data\" in x:\n",
    "            continue\n",
    "        cs = x.split(' ')\n",
    "        if \"@attribute\" in cs:\n",
    "            if flag == 1:\n",
    "                tof.write(',')\n",
    "            tof.write(cs[1])\n",
    "            flag = 1\n",
    "        else:\n",
    "            tof.write(x)\n",
    "    f.close()\n",
    "    tof.close()\n",
    "\n",
    "csv_data= arff_to_csv(\"ThoraricSurgery.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOlbcJ4EIYHd"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "ThoraricSurgery = pd.read_csv(\"ThoraricSurgery.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC14</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRZ2</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DGN  PRE4  PRE5  PRE6 PRE7 PRE8 PRE9 PRE10 PRE11 PRE14 PRE17 PRE19  \\\n",
       "0    DGN2   2.9   2.2  PRZ1    F    F    F     T     T  OC14     F     F   \n",
       "1    DGN3   3.4   1.9  PRZ0    F    F    F     F     F  OC12     F     F   \n",
       "2    DGN3   2.8   2.1  PRZ1    F    F    F     T     F  OC11     F     F   \n",
       "3    DGN3   3.7   3.0  PRZ0    F    F    F     F     F  OC11     F     F   \n",
       "4    DGN3   2.4   1.0  PRZ2    F    T    F     T     T  OC11     F     F   \n",
       "..    ...   ...   ...   ...  ...  ...  ...   ...   ...   ...   ...   ...   \n",
       "465  DGN2   3.9   2.1  PRZ1    F    F    F     T     F  OC13     F     F   \n",
       "466  DGN3   3.8   3.1  PRZ0    F    F    F     F     F  OC11     F     F   \n",
       "467  DGN3   3.0   2.1  PRZ1    F    F    F     T     F  OC13     F     F   \n",
       "468  DGN3   2.0   1.7  PRZ1    F    F    F     T     T  OC12     F     F   \n",
       "469  DGN3   4.7   3.6  PRZ0    F    F    F     F     F  OC12     F     F   \n",
       "\n",
       "    PRE25 PRE30 PRE32  AGE Risk1Yr  \n",
       "0       F     T     F   60       F  \n",
       "1       F     T     F   51       F  \n",
       "2       F     T     F   59       F  \n",
       "3       F     F     F   54       F  \n",
       "4       F     T     F   73       T  \n",
       "..    ...   ...   ...  ...     ...  \n",
       "465     F     T     F   63       F  \n",
       "466     F     T     F   61       F  \n",
       "467     F     F     F   52       F  \n",
       "468     F     T     F   79       F  \n",
       "469     F     T     F   51       F  \n",
       "\n",
       "[470 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThoraricSurgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>86.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  \\\n",
       "count 470.0 470.0 470.0 470.0 470.0 470.0 470.0  470.0  470.0  470.0  470.0   \n",
       "mean    3.1   3.3   4.6   0.8   0.1   0.1   0.1    0.7    0.2   11.7    0.1   \n",
       "std     0.7   0.9  11.8   0.5   0.2   0.4   0.2    0.5    0.4    0.7    0.3   \n",
       "min     1.0   1.4   1.0   0.0   0.0   0.0   0.0    0.0    0.0   11.0    0.0   \n",
       "25%     3.0   2.6   2.0   0.0   0.0   0.0   0.0    0.0    0.0   11.0    0.0   \n",
       "50%     3.0   3.2   2.4   1.0   0.0   0.0   0.0    1.0    0.0   12.0    0.0   \n",
       "75%     3.0   3.8   3.1   1.0   0.0   0.0   0.0    1.0    0.0   12.0    0.0   \n",
       "max     8.0   6.3  86.3   2.0   1.0   1.0   1.0    1.0    1.0   14.0    1.0   \n",
       "\n",
       "       PRE19  PRE25  PRE30  PRE32   AGE  Risk1Yr  \n",
       "count  470.0  470.0  470.0  470.0 470.0    470.0  \n",
       "mean     0.0    0.0    0.8    0.0  62.5      0.1  \n",
       "std      0.1    0.1    0.4    0.1   8.7      0.4  \n",
       "min      0.0    0.0    0.0    0.0  21.0      0.0  \n",
       "25%      0.0    0.0    1.0    0.0  57.0      0.0  \n",
       "50%      0.0    0.0    1.0    0.0  62.0      0.0  \n",
       "75%      0.0    0.0    1.0    0.0  69.0      0.0  \n",
       "max      1.0    1.0    1.0    1.0  87.0      1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DGN_mapping = {\n",
    "    'DGN3': 3,\n",
    "    'DGN2': 2,\n",
    "    'DGN4': 4,\n",
    "    'DGN6': 6,\n",
    "    'DGN5': 5,\n",
    "    'DGN8': 8,\n",
    "    'DGN1': 1\n",
    "}\n",
    "PRZ_mapping = {\n",
    "    'PRZ0' : 0,\n",
    "    'PRZ1' : 1,\n",
    "    'PRZ2' : 2\n",
    "}\n",
    "OC_mapping = {\n",
    "    'OC11': 11,\n",
    "    'OC12': 12,\n",
    "    'OC13': 13,\n",
    "    'OC14': 14\n",
    "}\n",
    "TF_mapping = {\n",
    "    'T' : 1,\n",
    "    'F' : 0\n",
    "}\n",
    "ThoraricSurgery['DGN'] = ThoraricSurgery['DGN'].map(DGN_mapping)\n",
    "ThoraricSurgery['PRE6'] = ThoraricSurgery['PRE6'].map(PRZ_mapping)\n",
    "ThoraricSurgery['PRE14'] = ThoraricSurgery['PRE14'].map(OC_mapping)\n",
    "TFset = ['PRE7','PRE8','PRE9','PRE10','PRE11','PRE17','PRE19','PRE25','PRE30','PRE32','Risk1Yr']\n",
    "for x in TFset:\n",
    "    ThoraricSurgery[x] = ThoraricSurgery[x].map(TF_mapping)\n",
    "\n",
    "ThoraricSurgery.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_set = pd.DataFrame\n",
    "death_set = ThoraricSurgery[ThoraricSurgery[\"Risk1Yr\"] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>86.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  \\\n",
       "count 540.0 540.0 540.0 540.0 540.0 540.0 540.0  540.0  540.0  540.0  540.0   \n",
       "mean    3.1   3.3   4.4   0.8   0.1   0.2   0.1    0.7    0.2   11.8    0.1   \n",
       "std     0.8   0.9  11.4   0.5   0.3   0.4   0.3    0.5    0.4    0.7    0.3   \n",
       "min     1.0   1.4   1.0   0.0   0.0   0.0   0.0    0.0    0.0   11.0    0.0   \n",
       "25%     3.0   2.6   2.0   0.0   0.0   0.0   0.0    0.0    0.0   11.0    0.0   \n",
       "50%     3.0   3.1   2.4   1.0   0.0   0.0   0.0    1.0    0.0   12.0    0.0   \n",
       "75%     3.0   3.8   3.0   1.0   0.0   0.0   0.0    1.0    0.0   12.0    0.0   \n",
       "max     8.0   6.3  86.3   2.0   1.0   1.0   1.0    1.0    1.0   14.0    1.0   \n",
       "\n",
       "       PRE19  PRE25  PRE30  PRE32   AGE  Risk1Yr  \n",
       "count  540.0  540.0  540.0  540.0 540.0    540.0  \n",
       "mean     0.0    0.0    0.8    0.0  62.6      0.3  \n",
       "std      0.1    0.1    0.4    0.1   8.8      0.4  \n",
       "min      0.0    0.0    0.0    0.0  21.0      0.0  \n",
       "25%      0.0    0.0    1.0    0.0  57.0      0.0  \n",
       "50%      0.0    0.0    1.0    0.0  62.0      0.0  \n",
       "75%      0.0    0.0    1.0    0.0  69.0      1.0  \n",
       "max      1.0    1.0    1.0    1.0  87.0      1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = pd.DataFrame()\n",
    "california_housing_dataframe = ThoraricSurgery.append(death_set,ignore_index=True)\n",
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  \\\n",
       "355    3   3.7   3.2     1     0     0     0      1      0     12      0   \n",
       "110    2   4.5   4.2     0     0     0     0      0      0     12      0   \n",
       "8      3   3.2   2.6     2     0     0     0      1      1     11      0   \n",
       "260    3   2.7   2.1     0     0     0     0      0      0     14      0   \n",
       "313    3   2.6   1.8     1     0     0     0      1      0     12      0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...    ...   \n",
       "217    3   4.5   3.6     1     0     0     0      1      0     12      0   \n",
       "434    3   3.1   2.3     1     0     0     0      1      0     11      0   \n",
       "333    4   2.2   1.8     0     0     0     0      0      0     11      0   \n",
       "88     5   2.7   1.8     2     0     1     0      1      1     11      0   \n",
       "445    3   2.7   1.8     0     0     0     0      0      0     11      0   \n",
       "\n",
       "     PRE19  PRE25  PRE30  PRE32  AGE  Risk1Yr  \n",
       "355      0      0      1      0   55        0  \n",
       "110      0      0      1      0   55        0  \n",
       "8        0      0      1      0   68        0  \n",
       "260      0      0      0      0   69        1  \n",
       "313      0      0      1      0   70        0  \n",
       "..     ...    ...    ...    ...  ...      ...  \n",
       "217      0      0      1      0   76        0  \n",
       "434      0      0      1      0   57        0  \n",
       "333      0      0      0      0   71        0  \n",
       "88       0      0      1      0   76        0  \n",
       "445      0      0      1      0   63        0  \n",
       "\n",
       "[540 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTB73MNeIYHf"
   },
   "source": [
    " 注意以下代码与之前练习中的代码之间稍有不同。我们并没有将 `median_house_value` 用作目标，而是创建了一个新的二元目标 `median_house_value_is_high`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPSqspaqIYHg"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(california_housing_dataframe):\n",
    "  \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "  \"\"\"\n",
    "  selected_features = california_housing_dataframe[\n",
    "    [\n",
    "     \"DGN\",\"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE14\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\",\"AGE\"\n",
    "    ]]\n",
    "  processed_features = selected_features.copy()\n",
    "  # Create a synthetic feature.\n",
    "  processed_features[\"vital_capacity\"] = (\n",
    "    california_housing_dataframe[\"PRE5\"] /\n",
    "    california_housing_dataframe[\"PRE4\"])\n",
    "  return processed_features\n",
    "\n",
    "def preprocess_targets(california_housing_dataframe):\n",
    "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "  \"\"\"\n",
    "  output_targets = pd.DataFrame()\n",
    "  # Create a boolean categorical feature representing whether the\n",
    "  # median_house_value is above a set threshold.\n",
    "  output_targets[\"one_will_die\"] = california_housing_dataframe[\"Risk1Yr\"] \n",
    "  return output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_transform_features(source_df):\n",
    "  selected_examples = pd.DataFrame()\n",
    "  for r in range(1, 9):\n",
    "    selected_examples[\"DGN%d\" % r] = source_df[\"DGN\"].apply(lambda x: 1.0 if x == r else 0.0)\n",
    "  for r in range(11, 15):\n",
    "    selected_examples[\"part%d\" % r] = source_df[\"PRE14\"].apply(lambda x: 1.0 if x == r else 0.0)\n",
    "  for r in range(0, 100, 10):\n",
    "    selected_examples[\"age%d\" % r] = source_df[\"AGE\"].apply(lambda x: 1.0 if x >= r and x < r+10 else 0.0)\n",
    "  column_names = [\"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\"]\n",
    "  for r in column_names:\n",
    "    selected_examples[r] = source_df[r]\n",
    "  return selected_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = preprocess_features(california_housing_dataframe.head(10))\n",
    "training_examples = select_and_transform_features(training_examples)\n",
    "# training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwOYWmXqWA6D",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN1</th>\n",
       "      <th>DGN2</th>\n",
       "      <th>DGN3</th>\n",
       "      <th>DGN4</th>\n",
       "      <th>DGN5</th>\n",
       "      <th>DGN6</th>\n",
       "      <th>DGN7</th>\n",
       "      <th>DGN8</th>\n",
       "      <th>part11</th>\n",
       "      <th>part12</th>\n",
       "      <th>...</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN7  DGN8  part11  part12  ...    \\\n",
       "count 432.0 432.0 432.0 432.0 432.0 432.0 432.0 432.0   432.0   432.0  ...     \n",
       "mean    0.0   0.1   0.7   0.1   0.0   0.0   0.0   0.0     0.4     0.5  ...     \n",
       "std     0.0   0.3   0.5   0.3   0.2   0.1   0.0   0.1     0.5     0.5  ...     \n",
       "min     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0     0.0  ...     \n",
       "25%     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0     0.0  ...     \n",
       "50%     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0     0.0     1.0  ...     \n",
       "75%     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0     1.0     1.0  ...     \n",
       "max     1.0   1.0   1.0   1.0   1.0   1.0   0.0   1.0     1.0     1.0  ...     \n",
       "\n",
       "       PRE7  PRE8  PRE9  PRE10  PRE11  PRE17  PRE19  PRE25  PRE30  PRE32  \n",
       "count 432.0 432.0 432.0  432.0  432.0  432.0  432.0  432.0  432.0  432.0  \n",
       "mean    0.1   0.2   0.1    0.7    0.2    0.1    0.0    0.0    0.8    0.0  \n",
       "std     0.3   0.4   0.3    0.5    0.4    0.3    0.0    0.1    0.4    0.0  \n",
       "min     0.0   0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "25%     0.0   0.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "50%     0.0   0.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "75%     0.0   0.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "max     1.0   1.0   1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation examples summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN1</th>\n",
       "      <th>DGN2</th>\n",
       "      <th>DGN3</th>\n",
       "      <th>DGN4</th>\n",
       "      <th>DGN5</th>\n",
       "      <th>DGN6</th>\n",
       "      <th>DGN7</th>\n",
       "      <th>DGN8</th>\n",
       "      <th>part11</th>\n",
       "      <th>part12</th>\n",
       "      <th>...</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN7  DGN8  part11  part12  ...    \\\n",
       "count 108.0 108.0 108.0 108.0 108.0 108.0 108.0 108.0   108.0   108.0  ...     \n",
       "mean    0.0   0.1   0.8   0.1   0.0   0.0   0.0   0.0     0.3     0.6  ...     \n",
       "std     0.0   0.3   0.4   0.3   0.2   0.1   0.0   0.0     0.5     0.5  ...     \n",
       "min     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0     0.0  ...     \n",
       "25%     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0     0.0     0.0  ...     \n",
       "50%     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0     0.0     1.0  ...     \n",
       "75%     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0     1.0     1.0  ...     \n",
       "max     0.0   1.0   1.0   1.0   1.0   1.0   0.0   0.0     1.0     1.0  ...     \n",
       "\n",
       "       PRE7  PRE8  PRE9  PRE10  PRE11  PRE17  PRE19  PRE25  PRE30  PRE32  \n",
       "count 108.0 108.0 108.0  108.0  108.0  108.0  108.0  108.0  108.0  108.0  \n",
       "mean    0.0   0.1   0.0    0.7    0.2    0.1    0.0    0.0    0.8    0.0  \n",
       "std     0.2   0.4   0.2    0.5    0.4    0.3    0.1    0.2    0.4    0.1  \n",
       "min     0.0   0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "25%     0.0   0.0   0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "50%     0.0   0.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "75%     0.0   0.0   0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
       "max     1.0   1.0   1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training targets summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_will_die</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       one_will_die\n",
       "count         432.0\n",
       "mean            0.3\n",
       "std             0.4\n",
       "min             0.0\n",
       "25%             0.0\n",
       "50%             0.0\n",
       "75%             1.0\n",
       "max             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation targets summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_will_die</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       one_will_die\n",
       "count         108.0\n",
       "mean            0.2\n",
       "std             0.4\n",
       "min             0.0\n",
       "25%             0.0\n",
       "50%             0.0\n",
       "75%             0.0\n",
       "max             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the first 12000 (out of 17000) examples for training.\n",
    "training_size = int(540 * 0.8)\n",
    "training_examples = preprocess_features(california_housing_dataframe.head(training_size))\n",
    "training_targets = preprocess_targets(california_housing_dataframe.head(training_size))\n",
    "\n",
    "# Choose the last 5000 (out of 17000) examples for validation.\n",
    "validation_size = int(540*0.2)\n",
    "validation_examples = preprocess_features(california_housing_dataframe.tail(validation_size))\n",
    "validation_targets = preprocess_targets(california_housing_dataframe.tail(validation_size))\n",
    "\n",
    "training_examples = select_and_transform_features(training_examples)\n",
    "validation_examples = select_and_transform_features(validation_examples)\n",
    "\n",
    "# Double-check that we've done the right thing.\n",
    "print(\"Training examples summary:\")\n",
    "display.display(training_examples.describe())\n",
    "print(\"Validation examples summary:\")\n",
    "display.display(validation_examples.describe())\n",
    "\n",
    "print(\"Training targets summary:\")\n",
    "display.display(training_targets.describe())\n",
    "print(\"Validation targets summary:\")\n",
    "display.display(validation_targets.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uon1LB3A31VN"
   },
   "source": [
    " ## 线性回归会有怎样的表现？\n",
    "为了解逻辑回归为什么有效，我们首先训练一个使用线性回归的简单模型。该模型将使用 `{0, 1}` 中的值为标签，并尝试预测一个尽可能接近 `0` 或 `1` 的连续值。此外，我们希望将输出解读为概率，所以最好模型的输出值可以位于 `(0, 1)` 范围内。然后我们会应用阈值 `0.5`，以确定标签。\n",
    "\n",
    "运行以下单元格，以使用 [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) 训练线性回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile_based_boundaries(feature_values, num_buckets):\n",
    "  boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "  quantiles = feature_values.quantile(boundaries)\n",
    "  return [quantiles[q] for q in quantiles.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smmUYRDtWOV_"
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns(input_features):\n",
    "  \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "  Args:\n",
    "    input_features: The names of the numerical input features to use.\n",
    "  Returns:\n",
    "    A set of feature columns\n",
    "  \"\"\"\n",
    "#   age = tf.feature_column.numeric_column(\"AGE\")\n",
    "#   bucketized_age = tf.feature_column.bucketized_column(\n",
    "#     age, boundaries=get_quantile_based_boundaries(\n",
    "#       training_examples[\"AGE\"], 10)\n",
    "#   )\n",
    "  feature_columns = set([tf.feature_column.numeric_column(my_feature)\n",
    "              for my_feature in input_features])\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5OwSrr1yIKD"
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                            \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SE2-hq8PIYHz"
   },
   "outputs": [],
   "source": [
    "def train_linear_regressor_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear regression model.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  as well as a plot of the training and validation loss over time.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    training_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for training.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "      \n",
    "  Returns:\n",
    "    A `LinearRegressor` object trained on the training data.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  # Create a linear regressor object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=construct_feature_columns(training_examples),\n",
    "      optimizer=my_optimizer\n",
    "  )\n",
    "    \n",
    "  # Create input functions.  \n",
    "  training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    batch_size=batch_size)\n",
    "  predict_training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "  predict_validation_input_fn = lambda: my_input_fn(\n",
    "    validation_examples, \n",
    "    validation_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"RMSE (on training data):\")\n",
    "  training_rmse = []\n",
    "  validation_rmse = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    \n",
    "    # Take a break and compute predictions.\n",
    "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
    "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "    \n",
    "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "        \n",
    "    # Compute training and validation loss.\n",
    "    training_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(training_predictions, training_targets))\n",
    "    validation_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_rmse.append(training_root_mean_squared_error)\n",
    "    validation_rmse.append(validation_root_mean_squared_error)\n",
    "  print(\"Model training finished.\")\n",
    "  \n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"RMSE\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(training_rmse, label=\"training\")\n",
    "  plt.plot(validation_rmse, label=\"validation\")\n",
    "  plt.legend()\n",
    "\n",
    "  return linear_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDBD8xeeIYH2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 0.43\n",
      "  period 01 : 0.43\n",
      "  period 02 : 0.42\n",
      "  period 03 : 0.42\n",
      "  period 04 : 0.42\n",
      "  period 05 : 0.41\n",
      "  period 06 : 0.41\n",
      "  period 07 : 0.41\n",
      "  period 08 : 0.41\n",
      "  period 09 : 0.41\n",
      "Model training finished.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_regressor = train_linear_regressor_model(\n",
    "    learning_rate=0.001,\n",
    "    steps=800,\n",
    "    batch_size=20,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXFQ5uig2RoP",
    "solution": "shown"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_validation_input_fn = lambda: my_input_fn(\n",
    "    validation_examples, \n",
    "    validation_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "\n",
    "validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "\n",
    "_ = plt.hist(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions\n",
       "count        108.0\n",
       "mean           0.2\n",
       "std            0.2\n",
       "min           -0.0\n",
       "25%            0.1\n",
       "50%            0.2\n",
       "75%            0.3\n",
       "max            0.8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predictions_dataframe = pd.DataFrame()\n",
    "validation_predictions_dataframe['predictions'] = validation_predictions\n",
    "validation_predictions_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取值有在 [0, 1] 之外的，还需要经 S 型函数转化到概率值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjBZ_q7aD9gh",
    "solution": "hidden"
   },
   "source": [
    " ## 任务 1：我们可以计算这些预测的对数损失函数吗？\n",
    "\n",
    "**检查预测，并确定是否可以使用它们来计算对数损失函数。**\n",
    "\n",
    "`LinearRegressor` 使用的是 L2 损失，在将输出解读为概率时，它并不能有效地惩罚误分类。例如，对于概率分别为 0.9 和 0.9999 的负分类样本是否被分类为正分类，二者之间的差异应该很大，但 L2 损失并不会明显区分这些情况。\n",
    "\n",
    "相比之下，`LogLoss`（对数损失函数）对这些\"置信错误\"的惩罚力度更大。请注意，`LogLoss` 的定义如下：\n",
    "\n",
    "$$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred}) - (1 - y) \\cdot log(1 - y_{pred})$$\n",
    "\n",
    "\n",
    "但我们首先需要获得预测值。我们可以使用 `LinearRegressor.predict` 获得预测值。\n",
    "\n",
    "我们可以使用预测和相应目标计算 `LogLoss` 吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解读 `LogLoss`（对数损失函数）：  \n",
    "当实际是负样本，y=0，$Log Loss = \\sum_{(x,y)\\in D} - log(1 - y_{pred})$，$y_{pred}$ 越大，损失越大。并且 0.9 和 0.9999 差异很大。  \n",
    "当实际是正样本，y=1，$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred})$，$y_{pred}$ 越小，损失越大。并且 0.1 和 0.0001 差异很大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYpy336F9wBg"
   },
   "source": [
    " ## 任务 2：训练逻辑回归模型并计算验证集的对数损失函数\n",
    "\n",
    "要使用逻辑回归非常简单，用 [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) 替代 `LinearRegressor` 即可。完成以下代码。\n",
    "\n",
    "**注意**：在 `LinearClassifier` 模型上运行 `train()` 和 `predict()` 时，您可以通过返回的字典（例如 `predictions[\"probabilities\"]`）中的 `\"probabilities\"` 键获取实值预测概率。Sklearn 的 [log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) 函数可基于这些概率计算对数损失函数，非常方便。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JElcb--E9wBm",
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "def train_linear_classifier_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear classification model.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  as well as a plot of the training and validation loss over time.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    training_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for training.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "      \n",
    "  Returns:\n",
    "    A `LinearClassifier` object trained on the training data.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "  \n",
    "  # Create a linear classifier object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_classifier = tf.estimator.LinearClassifier(\n",
    "      feature_columns=construct_feature_columns(training_examples),\n",
    "      optimizer=my_optimizer\n",
    "  )# YOUR CODE HERE: Construct the linear classifier.\n",
    "  \n",
    "  # Create input functions.\n",
    "  training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    batch_size=batch_size)\n",
    "  predict_training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "  predict_validation_input_fn = lambda: my_input_fn(\n",
    "    validation_examples, \n",
    "    validation_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "  \n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"LogLoss (on training data):\")\n",
    "  training_log_losses = []\n",
    "  validation_log_losses = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_classifier.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    # Take a break and compute predictions.    \n",
    "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
    "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
    "    \n",
    "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "    \n",
    "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
    "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_log_losses.append(training_log_loss)\n",
    "    validation_log_losses.append(validation_log_loss)\n",
    "  print(\"Model training finished.\")\n",
    "  \n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"LogLoss\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"LogLoss vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(training_log_losses, label=\"training\")\n",
    "  plt.plot(validation_log_losses, label=\"validation\")\n",
    "  plt.legend()\n",
    "\n",
    "  return linear_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VM0wmnFUIYH9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss (on training data):\n",
      "  period 00 : 0.56\n",
      "  period 01 : 0.54\n",
      "  period 02 : 0.53\n",
      "  period 03 : 0.53\n",
      "  period 04 : 0.52\n",
      "  period 05 : 0.52\n",
      "  period 06 : 0.51\n"
     ]
    }
   ],
   "source": [
    "linear_classifier = train_linear_classifier_model(\n",
    "    learning_rate=0.005,\n",
    "    steps=1000,\n",
    "    batch_size=20,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_predictions = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "validation_predictions = np.array([item['probabilities'][0] for item in validation_predictions])\n",
    "\n",
    "_ = plt.hist(validation_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-Xo83_aR6s_"
   },
   "source": [
    " ## 任务 3：计算准确率并为验证集绘制 ROC 曲线\n",
    "\n",
    "分类时非常有用的一些指标包括：模型[准确率](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)、[ROC 曲线](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)和 ROC 曲线下面积 (AUC)。我们会检查这些指标。\n",
    "\n",
    "`LinearClassifier.evaluate` 可计算准确率和 AUC 等实用指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKSQ87VVIYIA",
    "solution": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the validation set: 0.72\n",
      "Accuracy on the validation set: 0.76\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
    "\n",
    "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
    "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47xGS2uNIYIE"
   },
   "source": [
    " 您可以使用类别概率（例如由 `LinearClassifier.predict` \n",
    "和 Sklearn 的 [roc_curve](http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) 计算的概率）来获得绘制 ROC 曲线所需的真正例率和假正例率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xaU7ttj8IYIF",
    "solution": "hidden"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "# Get just the probabilities for the positive class.\n",
    "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
    "    validation_targets, validation_probabilities)\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
    "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
    "_ = plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIdhwfgzIYII"
   },
   "source": [
    " **看看您是否可以调整任务 2 中训练的模型的学习设置，以改善 AUC。**\n",
    "\n",
    "通常情况下，某些指标在提升的同时会损害其他指标，因此您需要找到可以实现理想折中情况的设置。\n",
    "\n",
    "**验证所有指标是否同时有所提升。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHosS1g2aetf",
    "solution": "shown"
   },
   "source": [
    " 一个可能有用的解决方案是，只要不过拟合，就训练更长时间。\n",
    "\n",
    "要做到这一点，我们可以增加步数和/或批量大小。\n",
    "\n",
    "所有指标同时提升，这样，我们的损失指标就可以很好地代理 AUC 和准确率了。\n",
    "\n",
    "注意它是如何进行很多很多次迭代，只是为了再尽量增加一点 AUC。这种情况很常见，但通常情况下，即使只有一点小小的收获，投入的成本也是值得的。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dPpJUV862FYI",
    "i2e3TlyL57Qs",
    "wCugvl0JdWYL",
    "copyright-notice"
   ],
   "include_colab_link": true,
   "name": "logistic_regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336.903px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
