{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/Baileyswu/google-tensorflow-tutor/blob/master/7.%20logistic_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4T-_IsVbweU"
   },
   "source": [
    " # 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEAHZv4rIYHX"
   },
   "source": [
    " **学习目标：**\n",
    "  * 将（在之前的练习中构建的）房屋价值中位数预测模型重新构建为二元分类模型\n",
    "  * 比较逻辑回归与线性回归解决二元分类问题的有效性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnkCZqdIIYHY"
   },
   "source": [
    " 与在之前的练习中一样，我们将使用加利福尼亚州住房数据集，但这次我们会预测某个城市街区的住房成本是否高昂，从而将其转换成一个二元分类问题。此外，我们还会暂时恢复使用默认特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pltCyy2K3dd"
   },
   "source": [
    " ## 将问题构建为二元分类问题\n",
    "\n",
    "数据集的目标是 `median_house_value`，它是一个数值（连续值）特征。我们可以通过向此连续值使用阈值来创建一个布尔值标签。\n",
    "\n",
    "我们希望通过某个城市街区的特征预测该街区的住房成本是否高昂。为了给训练数据和评估数据准备目标，我们针对房屋价值中位数定义了分类阈值 - 第 75 百分位数（约为 265000）。所有高于此阈值的房屋价值标记为 `1`，其他值标记为 `0`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67IJwZX1Vvjt"
   },
   "source": [
    " ## 设置\n",
    "\n",
    "运行以下单元格，以加载数据并准备输入特征和目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arff_to_csv(fpath):\n",
    "    #读取arff数据\n",
    "    if fpath.find('.arff') < 0:\n",
    "        print('the file is not .arff file')\n",
    "        return\n",
    "    f = open(fpath)\n",
    "    filename = fpath[:fpath.find('.arff')] + '.csv'\n",
    "    tof = open(filename, 'w+')\n",
    "    lines = f.readlines()\n",
    "    content = []\n",
    "    flag = 0\n",
    "    for x in lines:\n",
    "        if \"@relation\" in x or \"@data\" in x:\n",
    "            continue\n",
    "        cs = x.split(' ')\n",
    "        if \"@attribute\" in cs:\n",
    "            if flag == 1:\n",
    "                tof.write(',')\n",
    "            tof.write(cs[1])\n",
    "            flag = 1\n",
    "        else:\n",
    "            tof.write(x)\n",
    "    f.close()\n",
    "    tof.close()\n",
    "\n",
    "csv_data= arff_to_csv(\"predict_death/ThoraricSurgery.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOlbcJ4EIYHd"
   },
   "outputs": [],
   "source": [
    "ThoraricSurgery = pd.read_csv(\"predict_death/ThoraricSurgery.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC14</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>PRZ2</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.12</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.12</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.68</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.56</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DGN  PRE4  PRE5  PRE6 PRE7 PRE8 PRE9 PRE10 PRE11 PRE14 PRE17 PRE19  \\\n",
       "0    DGN2  2.88  2.16  PRZ1    F    F    F     T     T  OC14     F     F   \n",
       "1    DGN3  3.40  1.88  PRZ0    F    F    F     F     F  OC12     F     F   \n",
       "2    DGN3  2.76  2.08  PRZ1    F    F    F     T     F  OC11     F     F   \n",
       "3    DGN3  3.68  3.04  PRZ0    F    F    F     F     F  OC11     F     F   \n",
       "4    DGN3  2.44  0.96  PRZ2    F    T    F     T     T  OC11     F     F   \n",
       "..    ...   ...   ...   ...  ...  ...  ...   ...   ...   ...   ...   ...   \n",
       "465  DGN2  3.88  2.12  PRZ1    F    F    F     T     F  OC13     F     F   \n",
       "466  DGN3  3.76  3.12  PRZ0    F    F    F     F     F  OC11     F     F   \n",
       "467  DGN3  3.04  2.08  PRZ1    F    F    F     T     F  OC13     F     F   \n",
       "468  DGN3  1.96  1.68  PRZ1    F    F    F     T     T  OC12     F     F   \n",
       "469  DGN3  4.72  3.56  PRZ0    F    F    F     F     F  OC12     F     F   \n",
       "\n",
       "    PRE25 PRE30 PRE32  AGE Risk1Yr  \n",
       "0       F     T     F   60       F  \n",
       "1       F     T     F   51       F  \n",
       "2       F     T     F   59       F  \n",
       "3       F     F     F   54       F  \n",
       "4       F     T     F   73       T  \n",
       "..    ...   ...   ...  ...     ...  \n",
       "465     F     T     F   63       F  \n",
       "466     F     T     F   61       F  \n",
       "467     F     F     F   52       F  \n",
       "468     F     T     F   79       F  \n",
       "469     F     T     F   51       F  \n",
       "\n",
       "[470 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThoraricSurgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>470.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.10</td>\n",
       "      <td>3.28</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.17</td>\n",
       "      <td>11.74</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.53</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>11.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.71</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>86.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DGN   PRE4   PRE5   PRE6   PRE7   PRE8   PRE9  PRE10  PRE11  PRE14  \\\n",
       "count 470.00 470.00 470.00 470.00 470.00 470.00 470.00 470.00 470.00 470.00   \n",
       "mean    3.10   3.28   4.57   0.78   0.07   0.14   0.07   0.69   0.17  11.74   \n",
       "std     0.72   0.87  11.77   0.54   0.25   0.35   0.25   0.46   0.37   0.70   \n",
       "min     1.00   1.44   0.96   0.00   0.00   0.00   0.00   0.00   0.00  11.00   \n",
       "25%     3.00   2.60   1.96   0.00   0.00   0.00   0.00   0.00   0.00  11.00   \n",
       "50%     3.00   3.16   2.40   1.00   0.00   0.00   0.00   1.00   0.00  12.00   \n",
       "75%     3.00   3.81   3.08   1.00   0.00   0.00   0.00   1.00   0.00  12.00   \n",
       "max     8.00   6.30  86.30   2.00   1.00   1.00   1.00   1.00   1.00  14.00   \n",
       "\n",
       "       PRE17  PRE19  PRE25  PRE30  PRE32    AGE  Risk1Yr  \n",
       "count 470.00 470.00 470.00 470.00 470.00 470.00   470.00  \n",
       "mean    0.07   0.00   0.02   0.82   0.00  62.53     0.15  \n",
       "std     0.26   0.07   0.13   0.38   0.07   8.71     0.36  \n",
       "min     0.00   0.00   0.00   0.00   0.00  21.00     0.00  \n",
       "25%     0.00   0.00   0.00   1.00   0.00  57.00     0.00  \n",
       "50%     0.00   0.00   0.00   1.00   0.00  62.00     0.00  \n",
       "75%     0.00   0.00   0.00   1.00   0.00  69.00     0.00  \n",
       "max     1.00   1.00   1.00   1.00   1.00  87.00     1.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DGN_mapping = {\n",
    "    'DGN3': 3,\n",
    "    'DGN2': 2,\n",
    "    'DGN4': 4,\n",
    "    'DGN6': 6,\n",
    "    'DGN5': 5,\n",
    "    'DGN8': 8,\n",
    "    'DGN1': 1\n",
    "}\n",
    "PRZ_mapping = {\n",
    "    'PRZ0' : 0,\n",
    "    'PRZ1' : 1,\n",
    "    'PRZ2' : 2\n",
    "}\n",
    "OC_mapping = {\n",
    "    'OC11': 11,\n",
    "    'OC12': 12,\n",
    "    'OC13': 13,\n",
    "    'OC14': 14\n",
    "}\n",
    "TF_mapping = {\n",
    "    'T' : 1,\n",
    "    'F' : 0\n",
    "}\n",
    "ThoraricSurgery['DGN'] = ThoraricSurgery['DGN'].map(DGN_mapping)\n",
    "ThoraricSurgery['PRE6'] = ThoraricSurgery['PRE6'].map(PRZ_mapping)\n",
    "ThoraricSurgery['PRE14'] = ThoraricSurgery['PRE14'].map(OC_mapping)\n",
    "TFset = ['PRE7','PRE8','PRE9','PRE10','PRE11','PRE17','PRE19','PRE25','PRE30','PRE32','Risk1Yr']\n",
    "for x in TFset:\n",
    "    ThoraricSurgery[x] = ThoraricSurgery[x].map(TF_mapping)\n",
    "\n",
    "ThoraricSurgery.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_set = pd.DataFrame()\n",
    "death_set = ThoraricSurgery[ThoraricSurgery[\"Risk1Yr\"] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# death_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>5</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>3</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>4</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  \\\n",
       "4      3  2.44  0.96     2     0     1     0      1      1     11      0   \n",
       "6      3  4.36  3.28     1     0     0     0      1      0     12      1   \n",
       "7      2  3.19  2.50     1     0     0     0      1      0     11      0   \n",
       "13     2  3.98  3.06     2     0     0     0      1      1     14      0   \n",
       "24     8  4.32  3.20     0     0     0     0      0      0     11      0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...    ...   \n",
       "420    5  4.96  4.16     1     0     0     0      1      0     11      0   \n",
       "421    2  3.76  2.96     1     0     0     0      1      0     14      1   \n",
       "426    3  2.48  2.08     1     0     0     0      1      0     13      0   \n",
       "449    3  2.84  1.88     1     0     0     0      1      0     12      0   \n",
       "463    4  3.44  2.16     1     0     0     0      1      1     12      1   \n",
       "\n",
       "     PRE19  PRE25  PRE30  PRE32  AGE  Risk1Yr  \n",
       "4        0      0      1      0   73        1  \n",
       "6        0      0      1      0   59        1  \n",
       "7        0      1      1      0   66        1  \n",
       "13       0      0      1      0   80        1  \n",
       "24       0      0      0      0   58        1  \n",
       "..     ...    ...    ...    ...  ...      ...  \n",
       "420      0      0      1      0   62        1  \n",
       "421      0      0      0      0   64        1  \n",
       "426      0      0      1      0   54        1  \n",
       "449      0      0      1      0   53        1  \n",
       "463      0      0      1      0   57        1  \n",
       "\n",
       "[70 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "death_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "size = death_set['DGN'].count()\n",
    "random_table = {'PRE5', 'AGE'}\n",
    "for x in random_table:\n",
    "    death_set[x] = death_set[x] + (np.random.random(size)-0.5)*death_set[x].mean()/100\n",
    "# death_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>5</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>3</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>4</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  \\\n",
       "4      3  2.44  0.94     2     0     1     0      1      1     11      0   \n",
       "6      3  4.36  3.30     1     0     0     0      1      0     12      1   \n",
       "7      2  3.19  2.51     1     0     0     0      1      0     11      0   \n",
       "13     2  3.98  3.06     2     0     0     0      1      1     14      0   \n",
       "24     8  4.32  3.21     0     0     0     0      0      0     11      0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...    ...   \n",
       "420    5  4.96  4.16     1     0     0     0      1      0     11      0   \n",
       "421    2  3.76  2.97     1     0     0     0      1      0     14      1   \n",
       "426    3  2.48  2.08     1     0     0     0      1      0     13      0   \n",
       "449    3  2.84  1.88     1     0     0     0      1      0     12      0   \n",
       "463    4  3.44  2.16     1     0     0     0      1      1     12      1   \n",
       "\n",
       "     PRE19  PRE25  PRE30  PRE32   AGE  Risk1Yr  \n",
       "4        0      0      1      0 73.31        1  \n",
       "6        0      0      1      0 58.87        1  \n",
       "7        0      1      1      0 66.03        1  \n",
       "13       0      0      1      0 80.26        1  \n",
       "24       0      0      0      0 58.23        1  \n",
       "..     ...    ...    ...    ...   ...      ...  \n",
       "420      0      0      1      0 62.21        1  \n",
       "421      0      0      0      0 63.70        1  \n",
       "426      0      0      1      0 53.88        1  \n",
       "449      0      0      1      0 52.89        1  \n",
       "463      0      0      1      0 57.04        1  \n",
       "\n",
       "[70 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "death_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>540.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.11</td>\n",
       "      <td>3.27</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.18</td>\n",
       "      <td>11.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.64</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>86.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DGN   PRE4   PRE5   PRE6   PRE7   PRE8   PRE9  PRE10  PRE11  PRE14  \\\n",
       "count 540.00 540.00 540.00 540.00 540.00 540.00 540.00 540.00 540.00 540.00   \n",
       "mean    3.11   3.27   4.41   0.80   0.07   0.15   0.07   0.70   0.18  11.77   \n",
       "std     0.76   0.86  11.37   0.54   0.26   0.36   0.26   0.46   0.38   0.73   \n",
       "min     1.00   1.44   0.94   0.00   0.00   0.00   0.00   0.00   0.00  11.00   \n",
       "25%     3.00   2.60   1.97   0.00   0.00   0.00   0.00   0.00   0.00  11.00   \n",
       "50%     3.00   3.12   2.40   1.00   0.00   0.00   0.00   1.00   0.00  12.00   \n",
       "75%     3.00   3.80   3.04   1.00   0.00   0.00   0.00   1.00   0.00  12.00   \n",
       "max     8.00   6.30  86.30   2.00   1.00   1.00   1.00   1.00   1.00  14.00   \n",
       "\n",
       "       PRE17  PRE19  PRE25  PRE30  PRE32    AGE  Risk1Yr  \n",
       "count 540.00 540.00 540.00 540.00 540.00 540.00   540.00  \n",
       "mean    0.08   0.00   0.02   0.83   0.00  62.64     0.26  \n",
       "std     0.28   0.06   0.13   0.37   0.06   8.76     0.44  \n",
       "min     0.00   0.00   0.00   0.00   0.00  21.00     0.00  \n",
       "25%     0.00   0.00   0.00   1.00   0.00  57.00     0.00  \n",
       "50%     0.00   0.00   0.00   1.00   0.00  62.00     0.00  \n",
       "75%     0.00   0.00   0.00   1.00   0.00  69.00     1.00  \n",
       "max     1.00   1.00   1.00   1.00   1.00  87.00     1.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = pd.DataFrame()\n",
    "california_housing_dataframe = ThoraricSurgery.append(death_set,ignore_index=True)\n",
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>3</td>\n",
       "      <td>5.52</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>3</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11  PRE14  PRE17  \\\n",
       "502    3  2.73  2.11     1     0     1     0      1      0     12      0   \n",
       "243    3  4.36  3.92     1     0     0     0      0      0     11      0   \n",
       "260    3  2.72  2.09     0     0     0     0      0      0     14      0   \n",
       "93     3  6.08  4.92     0     0     0     0      0      0     11      0   \n",
       "125    3  2.83  1.96     1     0     0     0      1      0     12      0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...    ...   \n",
       "118    4  3.48  2.56     1     0     0     0      0      0     11      0   \n",
       "241    3  5.52  3.56     1     0     0     0      1      0     12      0   \n",
       "1      3  3.40  1.88     0     0     0     0      0      0     12      0   \n",
       "53     4  3.76  2.52     1     0     0     0      1      0     12      0   \n",
       "531    3  4.40  3.57     1     0     0     1      1      1     11      0   \n",
       "\n",
       "     PRE19  PRE25  PRE30  PRE32   AGE  Risk1Yr  \n",
       "502      0      0      1      0 60.72        1  \n",
       "243      0      0      1      0 47.00        0  \n",
       "260      0      0      0      0 69.00        1  \n",
       "93       0      0      1      0 50.00        0  \n",
       "125      0      0      1      0 71.00        0  \n",
       "..     ...    ...    ...    ...   ...      ...  \n",
       "118      0      0      1      0 57.00        0  \n",
       "241      0      0      1      0 64.00        0  \n",
       "1        0      0      1      0 51.00        0  \n",
       "53       0      0      1      0 75.00        0  \n",
       "531      0      0      1      0 60.10        1  \n",
       "\n",
       "[540 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTB73MNeIYHf"
   },
   "source": [
    " 注意以下代码与之前练习中的代码之间稍有不同。我们并没有将 `median_house_value` 用作目标，而是创建了一个新的二元目标 `median_house_value_is_high`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPSqspaqIYHg"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(california_housing_dataframe):\n",
    "  \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "  \"\"\"\n",
    "  selected_features = california_housing_dataframe[\n",
    "    [\n",
    "     \"DGN\",\"PRE4\",\"PRE5\",\"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE14\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\",\"AGE\"\n",
    "    ]]\n",
    "  processed_features = selected_features.copy()\n",
    "  # Create a synthetic feature.\n",
    "#   processed_features[\"vital_capacity\"] = (\n",
    "#     california_housing_dataframe[\"PRE5\"] /\n",
    "#     california_housing_dataframe[\"PRE4\"])\n",
    "  return processed_features\n",
    "\n",
    "def preprocess_targets(california_housing_dataframe):\n",
    "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "  \"\"\"\n",
    "  output_targets = pd.DataFrame()\n",
    "  # Create a boolean categorical feature representing whether the\n",
    "  # median_house_value is above a set threshold.\n",
    "  output_targets[\"one_will_die\"] = california_housing_dataframe[\"Risk1Yr\"] \n",
    "  return output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_transform_features(source_df):\n",
    "  selected_examples = pd.DataFrame()\n",
    "  for r in range(1, 9):\n",
    "    selected_examples[\"DGN%d\" % r] = source_df[\"DGN\"].apply(lambda x: 1.0 if x == r else 0.0)\n",
    "  for r in range(11, 15):\n",
    "    selected_examples[\"part%d\" % r] = source_df[\"PRE14\"].apply(lambda x: 1.0 if x == r else 0.0)\n",
    "  for r in range(0, 100, 10):\n",
    "    selected_examples[\"age%d\" % r] = source_df[\"AGE\"].apply(lambda x: 1.0 if x >= r and x < r+10 else 0.0)\n",
    "  column_names = [\"PRE4\",\"PRE5\",\"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\"]\n",
    "  for r in column_names:\n",
    "    selected_examples[r] = source_df[r]\n",
    "  return selected_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = preprocess_features(california_housing_dataframe.head(10))\n",
    "training_examples = select_and_transform_features(training_examples)\n",
    "# training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwOYWmXqWA6D",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN1</th>\n",
       "      <th>DGN2</th>\n",
       "      <th>DGN3</th>\n",
       "      <th>DGN4</th>\n",
       "      <th>DGN5</th>\n",
       "      <th>DGN6</th>\n",
       "      <th>DGN7</th>\n",
       "      <th>DGN8</th>\n",
       "      <th>part11</th>\n",
       "      <th>part12</th>\n",
       "      <th>...</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>...</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "      <td>432.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DGN1   DGN2   DGN3   DGN4   DGN5   DGN6   DGN7   DGN8  part11  part12  \\\n",
       "count 432.00 432.00 432.00 432.00 432.00 432.00 432.00 432.00  432.00  432.00   \n",
       "mean    0.00   0.12   0.73   0.09   0.04   0.01   0.00   0.00    0.37    0.53   \n",
       "std     0.05   0.32   0.44   0.29   0.21   0.10   0.00   0.07    0.48    0.50   \n",
       "min     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00    0.00    0.00   \n",
       "25%     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00    0.00    0.00   \n",
       "50%     0.00   0.00   1.00   0.00   0.00   0.00   0.00   0.00    0.00    1.00   \n",
       "75%     0.00   0.00   1.00   0.00   0.00   0.00   0.00   0.00    1.00    1.00   \n",
       "max     1.00   1.00   1.00   1.00   1.00   1.00   0.00   1.00    1.00    1.00   \n",
       "\n",
       "       ...     PRE7   PRE8   PRE9  PRE10  PRE11  PRE17  PRE19  PRE25  PRE30  \\\n",
       "count  ...   432.00 432.00 432.00 432.00 432.00 432.00 432.00 432.00 432.00   \n",
       "mean   ...     0.06   0.14   0.07   0.69   0.17   0.08   0.00   0.02   0.84   \n",
       "std    ...     0.24   0.35   0.26   0.46   0.38   0.27   0.05   0.14   0.37   \n",
       "min    ...     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "25%    ...     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   1.00   \n",
       "50%    ...     0.00   0.00   0.00   1.00   0.00   0.00   0.00   0.00   1.00   \n",
       "75%    ...     0.00   0.00   0.00   1.00   0.00   0.00   0.00   0.00   1.00   \n",
       "max    ...     1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   \n",
       "\n",
       "       PRE32  \n",
       "count 432.00  \n",
       "mean    0.00  \n",
       "std     0.07  \n",
       "min     0.00  \n",
       "25%     0.00  \n",
       "50%     0.00  \n",
       "75%     0.00  \n",
       "max     1.00  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation examples summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN1</th>\n",
       "      <th>DGN2</th>\n",
       "      <th>DGN3</th>\n",
       "      <th>DGN4</th>\n",
       "      <th>DGN5</th>\n",
       "      <th>DGN6</th>\n",
       "      <th>DGN7</th>\n",
       "      <th>DGN8</th>\n",
       "      <th>part11</th>\n",
       "      <th>part12</th>\n",
       "      <th>...</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>...</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DGN1   DGN2   DGN3   DGN4   DGN5   DGN6   DGN7   DGN8  part11  part12  \\\n",
       "count 108.00 108.00 108.00 108.00 108.00 108.00 108.00 108.00  108.00  108.00   \n",
       "mean    0.00   0.12   0.70   0.14   0.03   0.00   0.00   0.01    0.31    0.61   \n",
       "std     0.00   0.33   0.46   0.35   0.17   0.00   0.00   0.10    0.47    0.49   \n",
       "min     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00    0.00    0.00   \n",
       "25%     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00    0.00    0.00   \n",
       "50%     0.00   0.00   1.00   0.00   0.00   0.00   0.00   0.00    0.00    1.00   \n",
       "75%     0.00   0.00   1.00   0.00   0.00   0.00   0.00   0.00    1.00    1.00   \n",
       "max     0.00   1.00   1.00   1.00   1.00   0.00   0.00   1.00    1.00    1.00   \n",
       "\n",
       "       ...     PRE7   PRE8   PRE9  PRE10  PRE11  PRE17  PRE19  PRE25  PRE30  \\\n",
       "count  ...   108.00 108.00 108.00 108.00 108.00 108.00 108.00 108.00 108.00   \n",
       "mean   ...     0.10   0.20   0.08   0.72   0.19   0.10   0.01   0.01   0.81   \n",
       "std    ...     0.30   0.40   0.28   0.45   0.39   0.30   0.10   0.10   0.40   \n",
       "min    ...     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "25%    ...     0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   1.00   \n",
       "50%    ...     0.00   0.00   0.00   1.00   0.00   0.00   0.00   0.00   1.00   \n",
       "75%    ...     0.00   0.00   0.00   1.00   0.00   0.00   0.00   0.00   1.00   \n",
       "max    ...     1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   \n",
       "\n",
       "       PRE32  \n",
       "count 108.00  \n",
       "mean    0.00  \n",
       "std     0.00  \n",
       "min     0.00  \n",
       "25%     0.00  \n",
       "50%     0.00  \n",
       "75%     0.00  \n",
       "max     0.00  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training targets summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_will_die</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>432.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       one_will_die\n",
       "count        432.00\n",
       "mean           0.27\n",
       "std            0.45\n",
       "min            0.00\n",
       "25%            0.00\n",
       "50%            0.00\n",
       "75%            1.00\n",
       "max            1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation targets summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_will_die</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       one_will_die\n",
       "count        108.00\n",
       "mean           0.20\n",
       "std            0.40\n",
       "min            0.00\n",
       "25%            0.00\n",
       "50%            0.00\n",
       "75%            0.00\n",
       "max            1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the first 12000 (out of 17000) examples for training.\n",
    "training_size = int(540 * 0.8)\n",
    "training_examples = preprocess_features(california_housing_dataframe.head(training_size))\n",
    "training_targets = preprocess_targets(california_housing_dataframe.head(training_size))\n",
    "\n",
    "# Choose the last 5000 (out of 17000) examples for validation.\n",
    "validation_size = int(540*0.2)\n",
    "validation_examples = preprocess_features(california_housing_dataframe.tail(validation_size))\n",
    "validation_targets = preprocess_targets(california_housing_dataframe.tail(validation_size))\n",
    "\n",
    "training_examples = select_and_transform_features(training_examples)\n",
    "validation_examples = select_and_transform_features(validation_examples)\n",
    "\n",
    "# Double-check that we've done the right thing.\n",
    "print(\"Training examples summary:\")\n",
    "display.display(training_examples.describe())\n",
    "print(\"Validation examples summary:\")\n",
    "display.display(validation_examples.describe())\n",
    "\n",
    "print(\"Training targets summary:\")\n",
    "display.display(training_targets.describe())\n",
    "print(\"Validation targets summary:\")\n",
    "display.display(validation_targets.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uon1LB3A31VN"
   },
   "source": [
    " ## 线性回归会有怎样的表现？\n",
    "为了解逻辑回归为什么有效，我们首先训练一个使用线性回归的简单模型。该模型将使用 `{0, 1}` 中的值为标签，并尝试预测一个尽可能接近 `0` 或 `1` 的连续值。此外，我们希望将输出解读为概率，所以最好模型的输出值可以位于 `(0, 1)` 范围内。然后我们会应用阈值 `0.5`，以确定标签。\n",
    "\n",
    "运行以下单元格，以使用 [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) 训练线性回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile_based_boundaries(feature_values, num_buckets):\n",
    "  boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "  quantiles = feature_values.quantile(boundaries)\n",
    "  return [quantiles[q] for q in quantiles.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smmUYRDtWOV_"
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns(input_features):\n",
    "  \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "  Args:\n",
    "    input_features: The names of the numerical input features to use.\n",
    "  Returns:\n",
    "    A set of feature columns\n",
    "  \"\"\"\n",
    "#   age = tf.feature_column.numeric_column(\"AGE\")\n",
    "#   bucketized_age = tf.feature_column.bucketized_column(\n",
    "#     age, boundaries=get_quantile_based_boundaries(\n",
    "#       training_examples[\"AGE\"], 10)\n",
    "#   )\n",
    "  feature_columns = set([tf.feature_column.numeric_column(my_feature)\n",
    "              for my_feature in input_features])\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5OwSrr1yIKD"
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                            \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SE2-hq8PIYHz"
   },
   "outputs": [],
   "source": [
    "def train_linear_regressor_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear regression model.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  as well as a plot of the training and validation loss over time.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    training_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for training.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "      \n",
    "  Returns:\n",
    "    A `LinearRegressor` object trained on the training data.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  # Create a linear regressor object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=construct_feature_columns(training_examples),\n",
    "      optimizer=my_optimizer\n",
    "  )\n",
    "    \n",
    "  # Create input functions.  \n",
    "  training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    batch_size=batch_size)\n",
    "  predict_training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "  predict_validation_input_fn = lambda: my_input_fn(\n",
    "    validation_examples, \n",
    "    validation_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"RMSE (on training data):\")\n",
    "  training_rmse = []\n",
    "  validation_rmse = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    \n",
    "    # Take a break and compute predictions.\n",
    "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
    "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "    \n",
    "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "        \n",
    "    # Compute training and validation loss.\n",
    "    training_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(training_predictions, training_targets))\n",
    "    validation_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_rmse.append(training_root_mean_squared_error)\n",
    "    validation_rmse.append(validation_root_mean_squared_error)\n",
    "  print(\"Model training finished.\")\n",
    "  \n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"RMSE\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(training_rmse, label=\"training\")\n",
    "  plt.plot(validation_rmse, label=\"validation\")\n",
    "  plt.legend()\n",
    "\n",
    "  return linear_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDBD8xeeIYH2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 0.45\n",
      "  period 01 : 0.44\n",
      "  period 02 : 0.43\n",
      "  period 03 : 0.44\n",
      "  period 04 : 0.43\n",
      "  period 05 : 0.42\n",
      "  period 06 : 0.43\n",
      "  period 07 : 0.42\n",
      "  period 08 : 0.44\n",
      "  period 09 : 0.42\n",
      "Model training finished.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57610f33c8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_regressor = train_linear_regressor_model(\n",
    "    learning_rate=0.001,\n",
    "    steps=800,\n",
    "    batch_size=20,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXFQ5uig2RoP",
    "solution": "shown"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5659729400>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_validation_input_fn = lambda: my_input_fn(\n",
    "    validation_examples, \n",
    "    validation_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "\n",
    "validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "\n",
    "_ = plt.hist(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions\n",
       "count       108.00\n",
       "mean          0.27\n",
       "std           0.14\n",
       "min          -0.38\n",
       "25%           0.18\n",
       "50%           0.27\n",
       "75%           0.36\n",
       "max           0.58"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predictions_dataframe = pd.DataFrame()\n",
    "validation_predictions_dataframe['predictions'] = validation_predictions\n",
    "validation_predictions_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取值有在 [0, 1] 之外的，还需要经 S 型函数转化到概率值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjBZ_q7aD9gh",
    "solution": "hidden"
   },
   "source": [
    " ## 任务 1：我们可以计算这些预测的对数损失函数吗？\n",
    "\n",
    "**检查预测，并确定是否可以使用它们来计算对数损失函数。**\n",
    "\n",
    "`LinearRegressor` 使用的是 L2 损失，在将输出解读为概率时，它并不能有效地惩罚误分类。例如，对于概率分别为 0.9 和 0.9999 的负分类样本是否被分类为正分类，二者之间的差异应该很大，但 L2 损失并不会明显区分这些情况。\n",
    "\n",
    "相比之下，`LogLoss`（对数损失函数）对这些\"置信错误\"的惩罚力度更大。请注意，`LogLoss` 的定义如下：\n",
    "\n",
    "$$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred}) - (1 - y) \\cdot log(1 - y_{pred})$$\n",
    "\n",
    "\n",
    "但我们首先需要获得预测值。我们可以使用 `LinearRegressor.predict` 获得预测值。\n",
    "\n",
    "我们可以使用预测和相应目标计算 `LogLoss` 吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解读 `LogLoss`（对数损失函数）：  \n",
    "当实际是负样本，y=0，$Log Loss = \\sum_{(x,y)\\in D} - log(1 - y_{pred})$，$y_{pred}$ 越大，损失越大。并且 0.9 和 0.9999 差异很大。  \n",
    "当实际是正样本，y=1，$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred})$，$y_{pred}$ 越小，损失越大。并且 0.1 和 0.0001 差异很大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYpy336F9wBg"
   },
   "source": [
    " ## 任务 2：训练逻辑回归模型并计算验证集的对数损失函数\n",
    "\n",
    "要使用逻辑回归非常简单，用 [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) 替代 `LinearRegressor` 即可。完成以下代码。\n",
    "\n",
    "**注意**：在 `LinearClassifier` 模型上运行 `train()` 和 `predict()` 时，您可以通过返回的字典（例如 `predictions[\"probabilities\"]`）中的 `\"probabilities\"` 键获取实值预测概率。Sklearn 的 [log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) 函数可基于这些概率计算对数损失函数，非常方便。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JElcb--E9wBm",
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "def train_linear_classifier_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear classification model.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  as well as a plot of the training and validation loss over time.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    training_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for training.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "      \n",
    "  Returns:\n",
    "    A `LinearClassifier` object trained on the training data.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "  \n",
    "  # Create a linear classifier object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_classifier = tf.estimator.LinearClassifier(\n",
    "      feature_columns=construct_feature_columns(training_examples),\n",
    "      optimizer=my_optimizer\n",
    "  )# YOUR CODE HERE: Construct the linear classifier.\n",
    "  \n",
    "  # Create input functions.\n",
    "  training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    batch_size=batch_size)\n",
    "  predict_training_input_fn = lambda: my_input_fn(\n",
    "    training_examples, \n",
    "    training_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "  predict_validation_input_fn = lambda: my_input_fn(\n",
    "    validation_examples, \n",
    "    validation_targets[\"one_will_die\"], \n",
    "    num_epochs=1, \n",
    "    shuffle=False)\n",
    "  \n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"LogLoss (on training data):\")\n",
    "  training_log_losses = []\n",
    "  validation_log_losses = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_classifier.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    # Take a break and compute predictions.    \n",
    "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
    "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
    "    \n",
    "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "    \n",
    "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
    "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_log_losses.append(training_log_loss)\n",
    "    validation_log_losses.append(validation_log_loss)\n",
    "  print(\"Model training finished.\")\n",
    "  \n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"LogLoss\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"LogLoss vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(training_log_losses, label=\"training\")\n",
    "  plt.plot(validation_log_losses, label=\"validation\")\n",
    "  plt.legend()\n",
    "\n",
    "  return linear_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VM0wmnFUIYH9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss (on training data):\n",
      "  period 00 : 0.57\n",
      "  period 01 : 0.55\n",
      "  period 02 : 0.54\n",
      "  period 03 : 0.54\n",
      "  period 04 : 0.53\n",
      "  period 05 : 0.52\n",
      "  period 06 : 0.56\n",
      "  period 07 : 0.54\n",
      "  period 08 : 0.51\n"
     ]
    }
   ],
   "source": [
    "linear_classifier = train_linear_classifier_model(\n",
    "    learning_rate=0.005,\n",
    "    steps=1000,\n",
    "    batch_size=20,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "validation_predictions = np.array([item['probabilities'][0] for item in validation_predictions])\n",
    "\n",
    "_ = plt.hist(validation_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-Xo83_aR6s_"
   },
   "source": [
    " ## 任务 3：计算准确率并为验证集绘制 ROC 曲线\n",
    "\n",
    "分类时非常有用的一些指标包括：模型[准确率](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)、[ROC 曲线](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)和 ROC 曲线下面积 (AUC)。我们会检查这些指标。\n",
    "\n",
    "`LinearClassifier.evaluate` 可计算准确率和 AUC 等实用指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKSQ87VVIYIA",
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
    "\n",
    "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
    "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47xGS2uNIYIE"
   },
   "source": [
    " 您可以使用类别概率（例如由 `LinearClassifier.predict` \n",
    "和 Sklearn 的 [roc_curve](http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) 计算的概率）来获得绘制 ROC 曲线所需的真正例率和假正例率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xaU7ttj8IYIF",
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "# Get just the probabilities for the positive class.\n",
    "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
    "    validation_targets, validation_probabilities)\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
    "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
    "_ = plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIdhwfgzIYII"
   },
   "source": [
    " **看看您是否可以调整任务 2 中训练的模型的学习设置，以改善 AUC。**\n",
    "\n",
    "通常情况下，某些指标在提升的同时会损害其他指标，因此您需要找到可以实现理想折中情况的设置。\n",
    "\n",
    "**验证所有指标是否同时有所提升。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHosS1g2aetf",
    "solution": "shown"
   },
   "source": [
    " 一个可能有用的解决方案是，只要不过拟合，就训练更长时间。\n",
    "\n",
    "要做到这一点，我们可以增加步数和/或批量大小。\n",
    "\n",
    "所有指标同时提升，这样，我们的损失指标就可以很好地代理 AUC 和准确率了。\n",
    "\n",
    "注意它是如何进行很多很多次迭代，只是为了再尽量增加一点 AUC。这种情况很常见，但通常情况下，即使只有一点小小的收获，投入的成本也是值得的。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dPpJUV862FYI",
    "i2e3TlyL57Qs",
    "wCugvl0JdWYL",
    "copyright-notice"
   ],
   "include_colab_link": true,
   "name": "logistic_regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336.903px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
